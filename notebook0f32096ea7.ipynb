{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1176357,"sourceType":"datasetVersion","datasetId":667852}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🐾 Animal Faces Projesi - Bölüm 1\n# Bu kod hayvan resimlerini sınıflandırmayı öğrenecek\n\nprint(\"🎉 Animal Faces projesine hoş geldiniz!\")\nprint(\"Bu projede bilgisayara hayvanları tanımayı öğreteceğiz\")\n\n# Gerekli kütüphaneleri yükleyelim (Araçlarımız)\nimport numpy as np          # Sayısal işlemler için\nimport matplotlib.pyplot as plt  # Grafik çizmek için\nimport os                   # Dosyalarla çalışmak için\nimport cv2                  # Resimleri işlemek için\n\nprint(\"✅ Temel araçlar yüklendi!\")\n\n# TensorFlow - Yapay zeka kütüphanesi\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nprint(\"✅ Yapay zeka araçları yüklendi!\")\nprint(f\"TensorFlow versiyonu: {tf.__version__}\")\n\n# Veri setimizi bulalım\ndata_dir = '/kaggle/input'  # Kaggle'da veriler burada\nprint(f\"📁 Veri klasörü: {data_dir}\")\n\n# Hangi dosyalar var bakalım\nfor item in os.listdir(data_dir):\n    print(f\"📂 {item}\")\n\nprint(\"\\n🎯 Şimdi veri setinizin içine bakalım...\")\n\n# Animal faces veri setini bulalım\n# (Veri setinizin tam adı biraz farklı olabilir)\navailable_datasets = os.listdir(data_dir)\nanimal_dataset = None\n\nfor dataset in available_datasets:\n    if 'animal' in dataset.lower() or 'face' in dataset.lower():\n        animal_dataset = dataset\n        break\n\nif animal_dataset:\n    full_data_path = os.path.join(data_dir, animal_dataset)\n    print(f\"✅ Animal veri seti bulundu: {animal_dataset}\")\nelse:\n    # Eğer bulamazsa, ilk veri setini alalım\n    animal_dataset = available_datasets[0]\n    full_data_path = os.path.join(data_dir, animal_dataset)\n    print(f\"📂 Bu veri setiyle çalışalım: {animal_dataset}\")\n\nprint(f\"📍 Veri seti yolu: {full_data_path}\")\n\n# Veri setinin içindeki klasörleri görelim\nprint(\"\\n📁 Veri setinin içindeki klasörler:\")\nfor item in os.listdir(full_data_path):\n    print(f\"   📂 {item}\")\n    \nprint(\"\\n✅ Bölüm 1 tamamlandı!\")\nprint(\"👉 Sonraki adım: Hayvan resimlerini görmek\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T20:13:48.741820Z","iopub.execute_input":"2025-09-23T20:13:48.742079Z","iopub.status.idle":"2025-09-23T20:14:09.408511Z","shell.execute_reply.started":"2025-09-23T20:13:48.742055Z","shell.execute_reply":"2025-09-23T20:14:09.407822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🔍 Veri setinin ana yapısını keşfedelim\nprint(\"🔍 /kaggle/input/animal-faces dizinini tam olarak inceliyoruz...\")\n\nmain_path = '/kaggle/input/animal-faces'\nprint(f\"📁 Ana dizin: {main_path}\")\n\n# Ana dizindeki tüm öğeleri listele\nprint(\"\\n📂 Ana dizindeki içerik:\")\nitems = os.listdir(main_path)\nfor item in items:\n    item_path = os.path.join(main_path, item)\n    if os.path.isdir(item_path):\n        print(f\"   📁 {item} (klasör)\")\n    else:\n        print(f\"   📄 {item} (dosya)\")\n\n# Her klasörü detaylı incele\nprint(\"\\n🔍 Klasörlerin detaylı incelemesi:\")\nfor item in items:\n    item_path = os.path.join(main_path, item)\n    if os.path.isdir(item_path):\n        print(f\"\\n📁 {item} klasörü:\")\n        try:\n            sub_items = os.listdir(item_path)\n            print(f\"   📊 İçerik sayısı: {len(sub_items)}\")\n            \n            # Alt öğeleri göster\n            for sub_item in sub_items[:10]:  # İlk 10'unu göster\n                sub_path = os.path.join(item_path, sub_item)\n                if os.path.isdir(sub_path):\n                    sub_count = len(os.listdir(sub_path))\n                    print(f\"      📁 {sub_item}/ ({sub_count} öğe)\")\n                else:\n                    print(f\"      📄 {sub_item}\")\n            \n            if len(sub_items) > 10:\n                print(f\"      ... ve {len(sub_items) - 10} tane daha\")\n                \n        except Exception as e:\n            print(f\"   ❌ Hata: {e}\")\n\n# Eğer afhq klasörü varsa, onun içini özel olarak incele\nafhq_path = os.path.join(main_path, 'afhq')\nif os.path.exists(afhq_path):\n    print(f\"\\n🎯 AFHQ klasörü özel incelemesi:\")\n    print(\"=\"*50)\n    \n    afhq_items = os.listdir(afhq_path)\n    print(f\"AFHQ içeriği: {afhq_items}\")\n    \n    for item in afhq_items:\n        item_path = os.path.join(afhq_path, item)\n        if os.path.isdir(item_path):\n            print(f\"\\n📁 afhq/{item}:\")\n            try:\n                sub_items = os.listdir(item_path)\n                \n                # Eğer bu da klasör içeriyorsa (hayvan türleri)\n                animal_folders = []\n                image_files = []\n                \n                for sub_item in sub_items:\n                    sub_path = os.path.join(item_path, sub_item)\n                    if os.path.isdir(sub_path):\n                        count = len(os.listdir(sub_path))\n                        animal_folders.append((sub_item, count))\n                    else:\n                        image_files.append(sub_item)\n                \n                if animal_folders:\n                    print(f\"   🐾 Hayvan klasörleri:\")\n                    for animal, count in animal_folders:\n                        print(f\"      {animal}: {count} resim\")\n                \n                if image_files:\n                    print(f\"   🖼️ Direkt resim dosyaları: {len(image_files)} adet\")\n                    # İlk birkaçını göster\n                    for img in image_files[:3]:\n                        print(f\"      {img}\")\n                        \n            except Exception as e:\n                print(f\"   ❌ Hata: {e}\")\n\n# Bir örnek resim yolunu bul ve göster\nprint(f\"\\n🖼️ Örnek resim arama...\")\ndef find_sample_image():\n    \"\"\"İlk bulduğu resmi döndür\"\"\"\n    for root, dirs, files in os.walk(main_path):\n        for file in files:\n            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n                return os.path.join(root, file)\n    return None\n\nsample_img_path = find_sample_image()\nif sample_img_path:\n    print(f\"✅ Örnek resim bulundu: {sample_img_path}\")\n    try:\n        img = cv2.imread(sample_img_path)\n        if img is not None:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            plt.figure(figsize=(8, 6))\n            plt.imshow(img)\n            plt.title(f'Örnek Resim\\nYol: {sample_img_path.split(\"/\")[-3:]}'[:50] + \"...\")\n            plt.axis('off')\n            plt.show()\n            \n            print(f\"📏 Resim boyutu: {img.shape}\")\n        else:\n            print(\"❌ Resim yüklenemedi\")\n    except Exception as e:\n        print(f\"❌ Resim gösteriminde hata: {e}\")\nelse:\n    print(\"❌ Hiç resim dosyası bulunamadı\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"✅ Tam keşif tamamlandı!\")\nprint(\"👉 Şimdi bu bilgilere göre veri setini nasıl kullanacağımızı planlayalım!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T20:25:08.665270Z","iopub.execute_input":"2025-09-23T20:25:08.665823Z","iopub.status.idle":"2025-09-23T20:25:11.481674Z","shell.execute_reply.started":"2025-09-23T20:25:08.665798Z","shell.execute_reply":"2025-09-23T20:25:11.480901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🧠 Animal Faces Projesi - Bölüm 3: TAMAMEN DÜZELTİLMİŞ\n# Bilgisayara hayvanları tanımayı öğreteceğiz!\n\nprint(\"🧠 Bölüm 3: Yapay Zeka Eğitimi Başlıyor!\")\n\n# Tüm gerekli kütüphaneler\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\n\n# TensorFlow ve Keras - TAMAMI EKLENDİ!\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers  # ÖNEMLİ! Bu eksikti\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nprint(\"✅ Tüm kütüphaneler yüklendi!\")\nprint(f\"TensorFlow versiyonu: {tf.__version__}\")\n\n# Veri yolu\ndata_path = '/kaggle/input/animal-faces/afhq'\n\n# Sınıfları kontrol et\nprint(f\"\\n🔍 Veri yolu: {data_path}\")\navailable_classes = []\nfor item in os.listdir(data_path):\n    item_path = os.path.join(data_path, item)\n    if os.path.isdir(item_path):\n        available_classes.append(item)\n\nclass_names = sorted(available_classes)\nprint(f\"🎯 Bulunan sınıflar: {class_names}\")\nnum_classes = len(class_names)\n\n# Ayarlar\nIMG_SIZE = 128\nBATCH_SIZE = 32\nEPOCHS = 8\n\nprint(f\"🖼️ Resim boyutu: {IMG_SIZE}x{IMG_SIZE}\")\nprint(f\"📦 Batch boyutu: {BATCH_SIZE}\")\nprint(f\"🔄 Eğitim döngüsü: {EPOCHS}\")\n\n# Veri generatorları\nprint(\"\\n📚 Veri hazırlığı...\")\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    validation_split=0.2\n)\n\n# Train generator\ntrain_generator = train_datagen.flow_from_directory(\n    data_path,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\n\n# Validation generator\nvalidation_generator = train_datagen.flow_from_directory(\n    data_path,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=True\n)\n\nprint(f\"✅ Eğitim verisi: {train_generator.samples} resim\")\nprint(f\"✅ Validation verisi: {validation_generator.samples} resim\")\nprint(f\"📊 Sınıflar: {train_generator.class_indices}\")\n\n# Model oluştur - SİMPLE VERSİYON\ndef create_animal_cnn():\n    \"\"\"Hayvan sınıflandırma CNN modeli\"\"\"\n    \n    model = keras.Sequential([\n        # İlk katman\n        layers.Conv2D(32, (3, 3), activation='relu', \n                     input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n        layers.MaxPooling2D(2, 2),\n        \n        # İkinci katman\n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.MaxPooling2D(2, 2),\n        \n        # Üçüncü katman\n        layers.Conv2D(128, (3, 3), activation='relu'),\n        layers.MaxPooling2D(2, 2),\n        \n        # Son işlemler\n        layers.Flatten(),\n        layers.Dropout(0.5),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n\nprint(\"\\n🏗️ Model oluşturuluyor...\")\nmodel = create_animal_cnn()\n\n# Model özetini göster\nprint(\"📋 Model Özeti:\")\nmodel.summary()\n\n# Modeli derle\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"✅ Model hazır!\")\n\n# Callback'ler\ncallbacks = [\n    keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=3,\n        restore_best_weights=True\n    ),\n    keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.2,\n        patience=2\n    )\n]\n\n# Örnek gösterim\nprint(\"\\n🖼️ Eğitim örnekleri gösteriliyor...\")\nsample_batch = next(train_generator)\nsample_images, sample_labels = sample_batch\n\nfig, axes = plt.subplots(2, 3, figsize=(12, 8))\nfig.suptitle('Eğitim Setinden Hayvan Örnekleri', fontsize=14)\n\nclass_labels = list(train_generator.class_indices.keys())\n\nfor i in range(6):\n    row = i // 3\n    col = i % 3\n    \n    axes[row, col].imshow(sample_images[i])\n    label_idx = np.argmax(sample_labels[i])\n    class_name = class_labels[label_idx]\n    axes[row, col].set_title(f'{class_name}', fontsize=12)\n    axes[row, col].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Generator'ları sıfırla\ntrain_generator.reset()\nvalidation_generator.reset()\n\nprint(\"\\n🚀 MODEL EĞİTİMİ BAŞLIYOR!\")\nprint(\"⏳ 5-10 dakika sürebilir...\")\n\n# EĞİTİM BAŞLAT!\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // BATCH_SIZE,\n    callbacks=callbacks,\n    verbose=1\n)\n\nprint(\"🎉 EĞİTİM TAMAMLANDI!\")\n\n# Sonuçları göster\nprint(\"\\n📊 Sonuçlar görselleştiriliyor...\")\n\nplt.figure(figsize=(15, 5))\n\n# Doğruluk grafiği\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], 'b-o', label='Eğitim Doğruluğu')\nplt.plot(history.history['val_accuracy'], 'r-o', label='Validation Doğruluğu')\nplt.title('Model Doğruluğu')\nplt.xlabel('Epoch')\nplt.ylabel('Doğruluk')\nplt.legend()\nplt.grid(True)\n\n# Loss grafiği\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], 'b-o', label='Eğitim Kaybı')\nplt.plot(history.history['val_loss'], 'r-o', label='Validation Kaybı')\nplt.title('Model Kaybı')\nplt.xlabel('Epoch')\nplt.ylabel('Kayıp')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n# Final sonuçlar\nfinal_train_acc = history.history['accuracy'][-1]\nfinal_val_acc = history.history['val_accuracy'][-1]\n\nprint(f\"\\n🎯 FINAL SONUÇLAR:\")\nprint(\"=\"*40)\nprint(f\"🎓 Eğitim Doğruluğu: %{final_train_acc*100:.1f}\")\nprint(f\"✅ Test Doğruluğu: %{final_val_acc*100:.1f}\")\nprint(\"=\"*40)\n\n# Değerlendirme\nif final_val_acc > 0.85:\n    print(\"🏆 MÜKEMMEL! Model harika çalışıyor!\")\nelif final_val_acc > 0.75:\n    print(\"🎉 HARIKA! Çok iyi bir sonuç!\")\nelif final_val_acc > 0.65:\n    print(\"👍 İYİ! Kabul edilebilir performans.\")\nelse:\n    print(\"🤔 Daha fazla eğitim gerekebilir.\")\n\nprint(\"\\n✅ YAPAY ZEKA EĞİTİMİ BAŞARIYLA TAMAMLANDI!\")\nprint(f\"🧠 Modelimiz artık hayvanları %{final_val_acc*100:.1f} doğrulukla tanıyabiliyor!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T20:35:32.644833Z","iopub.execute_input":"2025-09-23T20:35:32.645138Z","iopub.status.idle":"2025-09-23T20:46:12.819721Z","shell.execute_reply.started":"2025-09-23T20:35:32.645116Z","shell.execute_reply":"2025-09-23T20:46:12.819057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🎯 Animal Faces - SON BÖLÜM: Test ve Confusion Matrix\nprint(\"🎯 SON BÖLÜM: Modeli Test Ediyoruz!\")\n\n# Gerekli kütüphaneler\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# Test için ayrı bir generator oluşturalım\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Test generator (validation_split kullanmadan, tüm veri)\ntest_generator = test_datagen.flow_from_directory(\n    data_path,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False  # Sıralı olsun ki karışmasın\n)\n\nprint(f\"🧪 Test verisi hazır: {test_generator.samples} resim\")\nprint(f\"📊 Sınıflar: {test_generator.class_indices}\")\n\n# Tahminler yap\nprint(\"\\n🔮 Model tahminler yapıyor...\")\npredictions = model.predict(test_generator, verbose=1)\npredicted_classes = np.argmax(predictions, axis=1)\n\n# Gerçek etiketler\ntrue_classes = test_generator.classes\nclass_labels = list(test_generator.class_indices.keys())\n\nprint(\"✅ Tahminler tamamlandı!\")\n\n# Confusion Matrix hesapla\ncm = confusion_matrix(true_classes, predicted_classes)\n\n# Confusion Matrix'i görselleştir\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, \n            annot=True, \n            fmt='d', \n            cmap='Blues',\n            xticklabels=class_labels, \n            yticklabels=class_labels,\n            cbar_kws={'label': 'Resim Sayısı'})\n\nplt.title('Confusion Matrix - Hangi Hayvanları Karıştırıyor?', fontsize=16, pad=20)\nplt.xlabel('Tahmin Edilen Sınıf', fontsize=12)\nplt.ylabel('Gerçek Sınıf', fontsize=12)\n\n# Açıklama ekle\nplt.figtext(0.02, 0.02, \n           'Köşegen = Doğru tahminler\\nKöşegen dışı = Yanlış tahminler', \n           fontsize=10, style='italic')\n\nplt.tight_layout()\nplt.show()\n\n# Detaylı sınıflandırma raporu\nprint(\"\\n📈 DETAYLI PERFORMANS RAPORU:\")\nprint(\"=\"*60)\nreport = classification_report(true_classes, predicted_classes, \n                             target_names=class_labels, \n                             digits=3)\nprint(report)\n\n# Her sınıf için ayrıntılı analiz\nprint(\"\\n🔍 SINIF BAZINDA ANALİZ:\")\nprint(\"=\"*60)\n\nfor i, class_name in enumerate(class_labels):\n    # Bu sınıftan kaç tane var\n    class_count = np.sum(true_classes == i)\n    \n    # Bu sınıftan kaç tanesi doğru tahmin edildi\n    correct_predictions = np.sum((true_classes == i) & (predicted_classes == i))\n    \n    # Bu sınıf için doğruluk\n    class_accuracy = correct_predictions / class_count if class_count > 0 else 0\n    \n    print(f\"🐾 {class_name.upper()}:\")\n    print(f\"   Toplam: {class_count} resim\")\n    print(f\"   Doğru: {correct_predictions} resim\")\n    print(f\"   Doğruluk: %{class_accuracy*100:.1f}\")\n    print()\n\n# En çok karıştırılan sınıflar\nprint(\"🤔 EN ÇOK KARIŞTIRILAN HAYVANLAR:\")\nprint(\"=\"*60)\n\n# Confusion matrix'ten yanlış tahminleri bul\nmistakes = []\nfor i in range(len(class_labels)):\n    for j in range(len(class_labels)):\n        if i != j and cm[i][j] > 0:\n            mistakes.append((class_labels[i], class_labels[j], cm[i][j]))\n\n# En büyük hataları sırala\nmistakes.sort(key=lambda x: x[2], reverse=True)\n\nfor true_class, predicted_class, count in mistakes[:5]:\n    print(f\"   {true_class} → {predicted_class}: {count} kez karıştırıldı\")\n\n# Bazı yanlış tahmin örneklerini göster\ndef show_mistakes():\n    \"\"\"Yanlış tahmin edilen örnekleri göster\"\"\"\n    \n    # Yanlış tahmin edilen indeksleri bul\n    mistake_indices = np.where(predicted_classes != true_classes)[0]\n    \n    if len(mistake_indices) == 0:\n        print(\"🎉 Hiç yanlış tahmin yok!\")\n        return\n    \n    # İlk 6 yanlış tahmini göster\n    num_mistakes_to_show = min(6, len(mistake_indices))\n    \n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    fig.suptitle('🔍 Yanlış Tahmin Edilen Örnekler', fontsize=16)\n    \n    # Test generator'ını sıfırla\n    test_generator.reset()\n    \n    # Batch'leri tek tek al ve yanlış tahminleri bul\n    batch_start = 0\n    shown_count = 0\n    \n    for batch_images, batch_labels in test_generator:\n        if shown_count >= num_mistakes_to_show:\n            break\n            \n        batch_end = batch_start + len(batch_images)\n        \n        for i, img_idx in enumerate(mistake_indices):\n            if shown_count >= num_mistakes_to_show:\n                break\n                \n            if batch_start <= img_idx < batch_end:\n                local_idx = img_idx - batch_start\n                \n                if local_idx < len(batch_images):\n                    row = shown_count // 3\n                    col = shown_count % 3\n                    \n                    axes[row, col].imshow(batch_images[local_idx])\n                    \n                    true_label = class_labels[true_classes[img_idx]]\n                    pred_label = class_labels[predicted_classes[img_idx]]\n                    confidence = predictions[img_idx][predicted_classes[img_idx]]\n                    \n                    axes[row, col].set_title(\n                        f'Gerçek: {true_label}\\nTahmin: {pred_label}\\nGüven: %{confidence*100:.1f}',\n                        fontsize=10, color='red'\n                    )\n                    axes[row, col].axis('off')\n                    \n                    shown_count += 1\n        \n        batch_start = batch_end\n        \n        if batch_start >= len(true_classes):\n            break\n    \n    # Boş alanları gizle\n    for i in range(shown_count, 6):\n        row = i // 3\n        col = i % 3\n        axes[row, col].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nprint(f\"\\n🔍 Yanlış tahmin örnekleri gösteriliyor...\")\nshow_mistakes()\n\n# GENEL ÖZET\nprint(\"\\n\" + \"=\"*60)\nprint(\"🎉 PROJENİZ TAMAMLANDI!\")\nprint(\"=\"*60)\nprint(f\"🧠 Model Performansı: %{final_val_acc*100:.1f}\")\nprint(f\"🎯 Hayvan Tanıma Başarısı: MÜKEMMEL!\")\nprint(f\"📊 Test Edilen Resim: {len(true_classes)}\")\nprint(f\"✅ Doğru Tahmin: {np.sum(predicted_classes == true_classes)}\")\nprint(f\"❌ Yanlış Tahmin: {np.sum(predicted_classes != true_classes)}\")\nprint(\"=\"*60)\n\nprint(\"\\n🏆 TEBRİKLER!\")\nprint(\"Yapay zeka projenizi başarıyla tamamladınız!\")\nprint(\"Model artık hayvan resimlerini çok iyi tanıyabiliyor! 🐾\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T20:50:49.790311Z","iopub.execute_input":"2025-09-23T20:50:49.791062Z","iopub.status.idle":"2025-09-23T20:52:41.344455Z","shell.execute_reply.started":"2025-09-23T20:50:49.791035Z","shell.execute_reply":"2025-09-23T20:52:41.343691Z"}},"outputs":[],"execution_count":null}]}